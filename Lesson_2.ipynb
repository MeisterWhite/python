{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yywOA57u8dOrTfW1avzLPWVbjCNam3NK",
      "authorship_tag": "ABX9TyMzo32p77168GwWJ6Ojxhq5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZo9zQI0Yknm"
      },
      "source": [
        "# Lesson 02\n",
        "# Парсинг HTML. BeautifulSoup, MongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QezSQwMYs6O"
      },
      "source": [
        "## Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайта superjob.ru и hh.ru. Приложение должно анализировать несколько страниц сайта(также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
        "\n",
        "1.   Наименование вакансии\n",
        "2.   Предлагаемую зарплату (отдельно мин. и и отдельно макс.)\n",
        "3.   Ссылку на саму вакансию\n",
        "4.   Сайт откуда собрана вакансия\n",
        "\n",
        "По своему желанию можно добавить еще работодателя и расположение. Данная структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSsXr15PYxPE"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqajaq6ZTuF"
      },
      "source": [
        "def _parser_hh(vacancy):\n",
        "\n",
        "    vacancy_date = []\n",
        "    \n",
        "    params = {\n",
        "        'text': vacancy, \\\n",
        "        'search_field': 'name', \\\n",
        "        'items_on_page': '100', \\\n",
        "        'page': ''\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0'\n",
        "    }\n",
        "\n",
        "    link = 'https://hh.ru/search/vacancy'\n",
        "       \n",
        "    html = requests.get(link, params=params, headers=headers)\n",
        "    \n",
        "    if html.ok:\n",
        "        parsed_html = bs(html.text,'html.parser')\n",
        "        \n",
        "        page_block = parsed_html.find('div', {'data-qa': 'pager-block'})\n",
        "        if not page_block:\n",
        "            last_page = '1'\n",
        "        else:\n",
        "            last_page = int(page_block.find_all('a', {'class': 'HH-Pager-Control'})[-1].getText())\n",
        "    \n",
        "    for page in range(0, last_page):\n",
        "        params['page'] = page\n",
        "        html = requests.get(link, params=params, headers=headers)\n",
        "        \n",
        "        if html.ok:\n",
        "            parsed_html = bs(html.text,'html.parser')\n",
        "            \n",
        "            vacancy_items = parsed_html.find('div', {'data-qa': 'vacancy-serp__results'}) \\\n",
        "                                        .find_all('div', {'class': 'vacancy-serp-item'})\n",
        "                \n",
        "            for item in vacancy_items:\n",
        "                vacancy_date.append(_parser_item_hh(item))\n",
        "                \n",
        "    return vacancy_date"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnKz0vOKZWpS"
      },
      "source": [
        "def _parser_item_hh(item):\n",
        "\n",
        "    vacancy_date = {}\n",
        "    \n",
        "    # vacancy_name\n",
        "    vacancy_name = item.find('div', {'class': 'resume-search-item__name'}) \\\n",
        "                        .getText() \\\n",
        "                        .replace(u'\\xa0', u' ')\n",
        "    \n",
        "    vacancy_date['vacancy_name'] = vacancy_name\n",
        "    \n",
        "    # company_name\n",
        "    company_name = item.find('div', {'class': 'vacancy-serp-item__meta-info'}) \\\n",
        "                        .find('a') \\\n",
        "                        .getText()\n",
        "    \n",
        "    vacancy_date['company_name'] = company_name\n",
        "    \n",
        "    # city\n",
        "    city = item.find('span', {'class': 'vacancy-serp-item__meta-info'}) \\\n",
        "                .getText() \\\n",
        "                .split(', ')[0]\n",
        "    \n",
        "    vacancy_date['city'] = city\n",
        "    \n",
        "    #metro station\n",
        "    metro_station = item.find('span', {'class': 'vacancy-serp-item__meta-info'}).findChild()\n",
        "\n",
        "    if not metro_station:\n",
        "        metro_station = None\n",
        "    else:\n",
        "        metro_station = metro_station.getText()\n",
        "        \n",
        "    vacancy_date['metro_station'] = metro_station\n",
        "    \n",
        "    #salary\n",
        "    salary = item.find('div', {'class': 'vacancy-serp-item__compensation'})\n",
        "    if not salary:\n",
        "        salary_min = None\n",
        "        salary_max = None\n",
        "        salary_currency = None\n",
        "    else:\n",
        "        salary = salary.getText() \\\n",
        "                        .replace(u'\\xa0', u'')\n",
        "        \n",
        "        salary = re.split(r'\\s|-', salary)\n",
        "        \n",
        "        if salary[0] == 'до':\n",
        "            salary_min = None\n",
        "            salary_max = int(salary[1])\n",
        "        elif salary[0] == 'от':\n",
        "            salary_min = int(salary[1])\n",
        "            salary_max = None\n",
        "        else:\n",
        "            salary_min = int(salary[0])\n",
        "            salary_max = int(salary[1])            \n",
        "        \n",
        "        salary_currency = salary[2]\n",
        "        \n",
        "    vacancy_date['salary_min'] = salary_min\n",
        "    vacancy_date['salary_max'] = salary_max\n",
        "    vacancy_date['salary_currency'] = salary_currency\n",
        "    \n",
        "    # link\n",
        "    is_ad = item.find('span', {'class': 'vacancy-serp-item__controls-item vacancy-serp-item__controls-item_last'}) \\\n",
        "                .getText()\n",
        "    \n",
        "    vacancy_link = item.find('div', {'class': 'resume-search-item__name'}) \\\n",
        "                        .find('a')['href']\n",
        "    \n",
        "    if is_ad != 'Реклама':\n",
        "        vacancy_link = vacancy_link.split('?')[0]\n",
        "    \n",
        "    vacancy_date['vacancy_link'] = vacancy_link \n",
        "    \n",
        "    # site\n",
        "    vacancy_date['site'] = 'hh.ru'\n",
        "    \n",
        "    return vacancy_date"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1wk7JGdZZfD"
      },
      "source": [
        "def _parser_superjob(vacancy):\n",
        "    vacancy_date = []\n",
        "    \n",
        "    params = {\n",
        "        'keywords': vacancy, \\\n",
        "        'profession_only': '1', \\\n",
        "        'geo[c][0]': '15', \\\n",
        "        'geo[c][1]': '1', \\\n",
        "        'geo[c][2]': '9', \\\n",
        "        'page': ''\n",
        "    }\n",
        "    \n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0'\n",
        "    }\n",
        "    \n",
        "    link = 'https://www.superjob.ru/vacancy/search/'\n",
        "       \n",
        "    html = requests.get(link, params=params, headers=headers)\n",
        "    \n",
        "    if html.ok:\n",
        "        parsed_html = bs(html.text,'html.parser')\n",
        "    \n",
        "        page_block = parsed_html.find('a', {'class': 'f-test-button-1'})\n",
        "    if not page_block:\n",
        "        last_page = 1\n",
        "    else:\n",
        "        page_block = page_block.findParent()\n",
        "        last_page = int(page_block.find_all('a')[-2].getText())\n",
        "    \n",
        "    for page in range(0, last_page + 1):\n",
        "        params['page'] = page\n",
        "        html = requests.get(link, params=params, headers=headers)\n",
        "        \n",
        "        if html.ok:\n",
        "            parsed_html = bs(html.text,'html.parser')\n",
        "            vacancy_items = parsed_html.find_all('div', {'class': 'f-test-vacancy-item'})\n",
        "                        \n",
        "            for item in vacancy_items:\n",
        "                vacancy_date.append(_parser_item_superjob(item))\n",
        "                \n",
        "    return vacancy_date"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyNZ8IrTZbre"
      },
      "source": [
        "def _parser_item_superjob(item):\n",
        "\n",
        "    vacancy_date = {}\n",
        "    \n",
        "    # vacancy_name\n",
        "    vacancy_name = item.find_all('a')\n",
        "    if len(vacancy_name) > 1:\n",
        "        vacancy_name = vacancy_name[-2].getText()\n",
        "    else:\n",
        "        vacancy_name = vacancy_name[0].getText()\n",
        "    vacancy_date['vacancy_name'] = vacancy_name\n",
        "    \n",
        "    # company_name\n",
        "    company_name = item.find('span', {'class': 'f-test-text-vacancy-item-company-name'})\n",
        "    \n",
        "    if not company_name:\n",
        "        company_name = item.findParent() \\\n",
        "                            .find('span', {'class': 'f-test-text-vacancy-item-company-name'}) \\\n",
        "                            .getText()\n",
        "    else:\n",
        "        company_name = company_name.getText()\n",
        "    \n",
        "    vacancy_date['company_name'] = company_name\n",
        "    \n",
        "    # city\n",
        "    company_location = item.find('span', {'class': 'f-test-text-company-item-location'}) \\\n",
        "                            .findChildren()[1] \\\n",
        "                            .getText() \\\n",
        "                            .split(',')\n",
        "    \n",
        "    vacancy_date['city'] = company_location[0]\n",
        "    \n",
        "    #metro station\n",
        "    if len(company_location) > 1:\n",
        "        metro_station = company_location[1]\n",
        "    else:\n",
        "        metro_station = None\n",
        "    \n",
        "    vacancy_date['metro_station'] = metro_station\n",
        "    \n",
        "    #salary\n",
        "    salary = item.find('span', {'class': 'f-test-text-company-item-salary'}) \\\n",
        "                  .findChildren()\n",
        "    if not salary:\n",
        "        salary_min = None\n",
        "        salary_max = None\n",
        "        salary_currency = None\n",
        "    else:\n",
        "        salary_currency = salary[-1].getText()\n",
        "        is_check_sarary = item.find('span', {'class': 'f-test-text-company-item-salary'}) \\\n",
        "                                .getText() \\\n",
        "                                .replace(u'\\xa0', u' ') \\\n",
        "                                .split(' ', 1)[0]\n",
        "        if is_check_sarary == 'до' or len(salary) == 2:\n",
        "            salary_min = None\n",
        "            salary_max = int(salary[0].getText() \\\n",
        "                                        .replace(u'\\xa0', u''))\n",
        "        elif is_check_sarary == 'от':\n",
        "            salary_min = int(salary[0].getText() \\\n",
        "                                         .replace(u'\\xa0', u''))\n",
        "            salary_max = None\n",
        "        else:\n",
        "            salary_min = int(salary[0].getText() \\\n",
        "                                         .replace(u'\\xa0', u''))\n",
        "            salary_max = int(salary[2].getText() \\\n",
        "                                         .replace(u'\\xa0', u''))           \n",
        "        \n",
        "    vacancy_date['salary_min'] = salary_min\n",
        "    vacancy_date['salary_max'] = salary_max\n",
        "    vacancy_date['salary_currency'] = salary_currency\n",
        "    \n",
        "    \n",
        "    # link\n",
        "    vacancy_link = item.find_all('a')\n",
        "    \n",
        "    if len(vacancy_link) > 1:\n",
        "        vacancy_link = vacancy_link[-2]['href']\n",
        "    else:\n",
        "        vacancy_link = vacancy_link[0]['href']\n",
        "    \n",
        "    vacancy_date['vacancy_link'] = f'https://www.superjob.ru{vacancy_link }'\n",
        "    \n",
        "    # site\n",
        "    vacancy_date['site'] = 'www.superjob.ru'\n",
        "    \n",
        "    return vacancy_date"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY5og-rlZeFJ"
      },
      "source": [
        "def parser_vacancy(vacancy):\n",
        "        \n",
        "    vacancy_date = []\n",
        "    vacancy_date.extend(_parser_hh(vacancy))\n",
        "    vacancy_date.extend(_parser_superjob(vacancy))\n",
        "    \n",
        "    df = pd.DataFrame(vacancy_date)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ngsKiqabVQK"
      },
      "source": [
        "vacancy = 'Python'\n",
        "df = parser_vacancy(vacancy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzw3IX2UbX4V"
      },
      "source": [
        "df[833:853]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}